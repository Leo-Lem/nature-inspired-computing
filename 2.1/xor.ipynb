{
 "cells": [
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "9c8b3084",
   "metadata": {},
   "source": [
    "# XOR ANN"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "164bbb05",
   "metadata": {},
   "source": [
    "## Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 165,
   "id": "eba87d78",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch.nn as nn\n",
    "\n",
    "class XOR_Classifier(nn.Module):\n",
    "    def __init__(self, num_inputs, num_hidden, num_outputs):\n",
    "        super().__init__()\n",
    "        # Initialize modules needed for this network\n",
    "        self.linear1 = nn.Linear(num_inputs, num_hidden)\n",
    "        self.activation = nn.Tanh()\n",
    "        self.linear2 = nn.Linear(num_hidden, num_outputs)\n",
    "        \n",
    "    def forward(self, x):\n",
    "        # Compute output given an input\n",
    "        x = self.linear1(x)\n",
    "        x = self.activation(x)\n",
    "        x = self.linear2(x)\n",
    "        return x"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "91bc0991",
   "metadata": {},
   "source": [
    "## Data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 166,
   "id": "ba99680b",
   "metadata": {},
   "outputs": [],
   "source": [
    "import torch\n",
    "import torch.utils.data as data\n",
    "\n",
    "class XOR_Dataset(data.Dataset):\n",
    "    def __init__(self, size, std=0.1):\n",
    "        \"\"\"\n",
    "        Inputs:\n",
    "            size - number of data points\n",
    "            std  - standard deviation of noise\n",
    "        \"\"\"\n",
    "        super().__init__()\n",
    "        self.size = size\n",
    "        self.std = std\n",
    "        self.generate_cont_xor()\n",
    "    \n",
    "    def generate_cont_xor(self):\n",
    "        data = torch.randint(low=0, high=2, size=(self.size, 2), dtype=torch.float32)\n",
    "        label = (data.sum(dim=1) == 1).to(torch.long)\n",
    "        data += self.std * torch.randn(data.shape)\n",
    "        \n",
    "        self.data = data\n",
    "        self.label = label\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.size\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        data_point = self.data[idx]\n",
    "        data_label = self.label[idx]\n",
    "        return data_point, data_label\n",
    "    "
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "1375af84",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 167,
   "id": "13564af5",
   "metadata": {},
   "outputs": [],
   "source": [
    "def train_model(model, optimizer, data_loader, loss_module, num_epochs=100):\n",
    "    model.train()\n",
    "    \n",
    "    for epoch in range(num_epochs):\n",
    "        for data_inputs, data_labels in data_loader:\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1) # Output is [Batch size, 1] but we want [Batch size]\n",
    "            \n",
    "            loss = loss_module(preds, data_labels.float())\n",
    "            \n",
    "            optimizer.zero_grad()\n",
    "            loss.backward()\n",
    "            \n",
    "            optimizer.step()"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "d0e2c4a9",
   "metadata": {},
   "source": [
    "## Evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 168,
   "id": "28250efb",
   "metadata": {},
   "outputs": [],
   "source": [
    "import matplotlib.pyplot as plt\n",
    "import numpy as np\n",
    "\n",
    "def plot_decision_boundary(model, data_loader):\n",
    "    model.eval()\n",
    "    \n",
    "    data_inputs, data_labels = data_loader.dataset.data, data_loader.dataset.label\n",
    "    data_inputs, data_labels = data_inputs.numpy(), data_labels.numpy()\n",
    "    \n",
    "    x_min, x_max = data_inputs[:, 0].min() - 0.1, data_inputs[:, 0].max() + 0.1\n",
    "    y_min, y_max = data_inputs[:, 1].min() - 0.1, data_inputs[:, 1].max() + 0.1\n",
    "    \n",
    "    xx, yy = np.meshgrid(np.arange(x_min, x_max, 0.01),\n",
    "                         np.arange(y_min, y_max, 0.01))\n",
    "    \n",
    "    Z = model(torch.from_numpy(np.c_[xx.ravel(), yy.ravel()]).float())\n",
    "    Z = Z.reshape(xx.shape)\n",
    "    \n",
    "    plt.contourf(xx, yy, Z.detach().numpy(), cmap=plt.cm.Spectral, alpha=0.8) # type: ignore\n",
    "    plt.scatter(data_inputs[:, 0], data_inputs[:, 1], c=data_labels, s=40, cmap=plt.cm.Spectral) # type: ignore\n",
    "    plt.xlim(xx.min(), xx.max())\n",
    "    plt.ylim(yy.min(), yy.max())\n",
    "    \n",
    "    plt.show()             \n",
    "\n",
    "def eval_model(model, data_loader, use_plots):\n",
    "    model.eval() # Set model to eval mode\n",
    "    true_preds, num_preds = 0., 0.\n",
    "    \n",
    "    with torch.no_grad(): # Deactivate gradients for the following code\n",
    "        for data_inputs, data_labels in data_loader:\n",
    "            \n",
    "            # Determine prediction of model on dev set\n",
    "            preds = model(data_inputs)\n",
    "            preds = preds.squeeze(dim=1)\n",
    "            preds = torch.sigmoid(preds) # Sigmoid to map predictions between 0 and 1\n",
    "            pred_labels = (preds >= 0.5).long() # Binarize predictions to 0 and 1\n",
    "            \n",
    "            # Keep records of predictions for the accuracy metric (true_preds=TP+TN, num_preds=TP+TN+FP+FN)\n",
    "            true_preds += (pred_labels == data_labels).sum()\n",
    "            num_preds += data_labels.shape[0]\n",
    "            \n",
    "    print(f\"accuracy: {100.0*true_preds / num_preds:4.2f}%\")\n",
    "    if use_plots: plot_decision_boundary(model, data_loader)"
   ]
  },
  {
   "attachments": {},
   "cell_type": "markdown",
   "id": "e298f100",
   "metadata": {},
   "source": [
    "## Adjustable ANN"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 170,
   "id": "189737d7",
   "metadata": {},
   "outputs": [],
   "source": [
    "class XOR:\n",
    "  def __init__(self, num_hidden):\n",
    "    self.model = XOR_Classifier(num_inputs=2, num_hidden=num_hidden, num_outputs=1)\n",
    "  \n",
    "  def train(self, std, num_epochs):\n",
    "    self.dataset = XOR_Dataset(size=2500, std=std)\n",
    "    self.test_dataset = XOR_Dataset(size=1500, std=std)\n",
    "\n",
    "    train_model(\n",
    "      self.model, \n",
    "      torch.optim.SGD(self.model.parameters(), lr=0.1), \n",
    "      data.DataLoader(self.dataset, batch_size=128, shuffle=True),\n",
    "      nn.BCEWithLogitsLoss(),\n",
    "      num_epochs=num_epochs\n",
    "    )\n",
    "\n",
    "  def eval(self, use_plots=False):\n",
    "    print(\"Training data \", end=\"\")\n",
    "    eval_model(\n",
    "      self.model, \n",
    "      data.DataLoader(self.dataset, batch_size=128, shuffle=False),\n",
    "      use_plots\n",
    "    )\n",
    "\n",
    "    print(\"Test data \", end=\"\")\n",
    "    eval_model(\n",
    "      self.model, \n",
    "      data.DataLoader(self.test_dataset, batch_size=128, shuffle=False, drop_last=False),\n",
    "      use_plots\n",
    "    )"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.11.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
